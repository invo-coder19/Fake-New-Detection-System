{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1334e184",
   "metadata": {},
   "source": [
    "# üì∞ Fake News Detection using Machine Learning\n",
    "This Jupyter Notebook implements a **Fake News Detection System** using machine learning techniques.\n",
    "\n",
    "**Contents:**\n",
    "- Introduction\n",
    "- Data Preprocessing\n",
    "- Model Training & Evaluation\n",
    "- Predicting Fake News\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "014f6e18",
   "metadata": {},
   "source": [
    "## üìå Introduction\n",
    "Fake news has become a critical issue in today's digital world. This project aims to classify news articles as **real** or **fake** using **Natural Language Processing (NLP)** techniques and **machine learning models**.\n",
    "\n",
    "**Goal:** Develop a model that accurately identifies fake news."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "753fa632",
   "metadata": {},
   "source": [
    "## üóÑÔ∏è Data Preprocessing\n",
    "Before building the model, we perform:\n",
    "- Loading the dataset\n",
    "- Removing missing values\n",
    "- Text preprocessing (lowercasing, stopword removal, stemming, etc.)\n",
    "- Vectorization using **TF-IDF** or **Count Vectorizer**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71f3a62b",
   "metadata": {},
   "source": [
    "## ü§ñ Model Training & Evaluation\n",
    "We train different machine learning models, such as:\n",
    "- **Logistic Regression**\n",
    "- **Na√Øve Bayes Classifier**\n",
    "- **Support Vector Machines (SVM)**\n",
    "- **Random Forest Classifier**\n",
    "\n",
    "We evaluate the models using accuracy, precision, recall, and F1-score."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc84f74c",
   "metadata": {},
   "source": [
    "## üì∞ Predicting Fake News\n",
    "After training the model, we test it by feeding new articles and classifying them as **real or fake**. The model outputs a prediction based on the trained algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a52d2c67",
   "metadata": {},
   "source": [
    "## üìå Conclusion\n",
    "This notebook demonstrates a **Fake News Detection System** using machine learning. Future improvements can include deep learning models like LSTMs or transformers (BERT, GPT) for better accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 208096,
     "status": "ok",
     "timestamp": 1740842975760,
     "user": {
      "displayName": "SIH",
      "userId": "08849459671356706912"
     },
     "user_tz": -330
    },
    "id": "puLWTgLyD2gi",
    "outputId": "fe39d2b7-e257-44da-f077-eacbaaa57aec"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9480\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.95      0.95      7010\n",
      "           1       0.95      0.95      0.95      7409\n",
      "\n",
      "    accuracy                           0.95     14419\n",
      "   macro avg       0.95      0.95      0.95     14419\n",
      "weighted avg       0.95      0.95      0.95     14419\n",
      "\n",
      "Enter a news paragraph to check if it's Fake or Real:\n",
      "All we can say on this one is it s about time someone sued the Southern Poverty Law Center!On Tuesday, D. James Kennedy Ministries (DJKM) filed a lawsuit against the Southern Poverty Law Center (SPLC), the charity navigation organization GuideStar, and Amazon, for defamation, religious discrimination, and trafficking in falsehood. The SPLC listed DJKM as a  hate group,  while GuideStar also categorized it in those terms, and Amazon kept the ministry off of its charity donation program, Amazon Smile. We embarked today on a journey to right a terrible wrong,  Dr. Frank Wright, president and CEO at DJKM, said in a statement Tuesday.  Those who knowingly label Christian ministries as  hate  groups, solely for subscribing to the historic Christian faith, are either woefully uninformed or willfully deceitful. In the case of the Southern Poverty Law Center, our lawsuit alleges the latter. The SPLC has labeled DJKM an  anti-LGBT hate group  for its opposition to same-sex marriage and transgenderism.  These false and illegal characterizations have a chilling effect on the free exercise of religion and on religious free speech for all people of faith,  Wright declared. After having given the SPLC an opportunity to retract, we have undertaken this legal action, seeking a trial by a jury of our peers, to preserve our own rights under the law and to defend the religious free speech rights of all Americans,  the DJKM president concluded.The lawsuit laid out charges against the SPLC, GuideStar, and Amazon.Read more: PJM\n",
      "Prediction: Real News ‚úÖ\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Load dataset\n",
    "file_path = \"WELFake_Dataset.csv\"  # Update path if needed\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Drop unnecessary index column if present\n",
    "if 'Unnamed: 0' in df.columns:\n",
    "    df = df.drop(columns=['Unnamed: 0'])\n",
    "\n",
    "# Fill missing titles with an empty string\n",
    "df['title'] = df['title'].fillna(\"\")\n",
    "\n",
    "# Drop rows where text is missing (text is essential)\n",
    "df = df.dropna(subset=['text'])\n",
    "\n",
    "# Combine title and text for processing\n",
    "df['content'] = df['title'] + \" \" + df['text']\n",
    "\n",
    "# Ensure labels are numeric (already 0 = Fake, 1 = Real)\n",
    "df['label'] = df['label'].astype(int)\n",
    "\n",
    "# Download necessary NLTK resources\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# Text preprocessing function\n",
    "def preprocess_text(text):\n",
    "    if not isinstance(text, str):  # Ensure input is a string\n",
    "        return \"\"\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'\\d+', '', text)  # Remove numbers\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))  # Remove punctuation\n",
    "    text = text.strip()\n",
    "    words = text.split()\n",
    "    words = [word for word in words if word not in stop_words]  # Remove stopwords\n",
    "    return \" \".join(words) if words else \"\"\n",
    "\n",
    "df['clean_text'] = df['content'].apply(preprocess_text)\n",
    "\n",
    "# Remove empty processed rows\n",
    "df = df.dropna(subset=['clean_text'])\n",
    "df = df[df['clean_text'].str.strip() != \"\"]\n",
    "\n",
    "# Vectorization using TF-IDF\n",
    "vectorizer = TfidfVectorizer(max_features=5000)\n",
    "X = vectorizer.fit_transform(df['clean_text'])\n",
    "y = df['label']\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Model training\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluation\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Function to predict if a news paragraph is real or fake\n",
    "def predict_news(news_text):\n",
    "    processed_text = preprocess_text(news_text)  # Preprocess input\n",
    "    transformed_text = vectorizer.transform([processed_text])  # Vectorize input\n",
    "    prediction = model.predict(transformed_text)[0]  # Predict (0 = Fake, 1 = Real)\n",
    "    return \"Real News ‚úÖ\" if prediction == 1 else \"Fake News ‚ùå\"\n",
    "\n",
    "# Example input\n",
    "news_paragraph = input(\"Enter a news paragraph to check if it's Fake or Real:\\n\")\n",
    "print(\"Prediction:\", predict_news(news_paragraph))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPENRkimRRl85xk4YlCZFBD",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
